{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-25T00:24:02.453173Z",
     "start_time": "2024-05-25T00:24:00.692802Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lzh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lzh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20,
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ],
   "id": "59696fab2c4230b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lzh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20,
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ],
   "id": "5dc8f995c068fd09"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lzh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20,
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ],
   "id": "4efb5ac589a09aed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T00:24:04.834887Z",
     "start_time": "2024-05-25T00:24:04.625352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the dataset\n",
    "data_path = '../datasets/learning-agency-lab-automated-essay-scoring-2/train.csv'\n",
    "test_path = '../datasets/learning-agency-lab-automated-essay-scoring-2/test.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "test = pd.read_csv(test_path)\n",
    "submission = pd.read_csv(test_path)\n",
    "data.head(5)"
   ],
   "id": "fddfb5dbf7694fb0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  essay_id                                          full_text  score\n",
       "0  000d118  Many people have car where they live. The thin...      3\n",
       "1  000fe60  I am a scientist at NASA that is discussing th...      3\n",
       "2  001ab80  People always wish they had the same technolog...      4\n",
       "3  001bdc0  We all heard about Venus, the planet without a...      4\n",
       "4  002ba53  Dear, State Senator\\n\\nThis is a letter to arg...      3"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>Many people have car where they live. The thin...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>I am a scientist at NASA that is discussing th...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>People always wish they had the same technolog...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001bdc0</td>\n",
       "      <td>We all heard about Venus, the planet without a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002ba53</td>\n",
       "      <td>Dear, State Senator\\n\\nThis is a letter to arg...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T00:24:07.779076Z",
     "start_time": "2024-05-25T00:24:07.418655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# text preprocessing\n",
    "import re\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # remove punctuation\n",
    "    text = text.lower() # lowercase text\n",
    "    text = text.replace('\\n', ' ') # remove new line\n",
    "    text = text.replace('&nbsp;', ' ') # remove html space\n",
    "    return text\n",
    "\n",
    "data['full_text'] = data['full_text'].apply(clean_text)\n",
    "test['full_text'] = test['full_text'].apply(clean_text)\n",
    "\n",
    "data.head(5)"
   ],
   "id": "1466211c9ec51a6c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  essay_id                                          full_text  score\n",
       "0  000d118  many people have car where they live the thing...      3\n",
       "1  000fe60  i am a scientist at nasa that is discussing th...      3\n",
       "2  001ab80  people always wish they had the same technolog...      4\n",
       "3  001bdc0  we all heard about venus the planet without al...      4\n",
       "4  002ba53  dear state senator  this is a letter to argue ...      3"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>many people have car where they live the thing...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>i am a scientist at nasa that is discussing th...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>people always wish they had the same technolog...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001bdc0</td>\n",
       "      <td>we all heard about venus the planet without al...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002ba53</td>\n",
       "      <td>dear state senator  this is a letter to argue ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T00:24:09.880867Z",
     "start_time": "2024-05-25T00:24:09.384257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.corpus import stopwords\n",
    "# Tokenization\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = text.split()\n",
    "    # filter out the stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    processed_tokens = ' '.join(tokens)\n",
    "    return processed_tokens\n",
    "\n",
    "data['full_text'] = data['full_text'].apply(tokenize)\n",
    "test['full_text'] = test['full_text'].apply(tokenize)\n",
    "\n",
    "data.head(5)"
   ],
   "id": "6c1f40f97cfb5d2e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  essay_id                                          full_text  score\n",
       "0  000d118  many people car live thing dont know use car a...      3\n",
       "1  000fe60  scientist nasa discussing face mars explaining...      3\n",
       "2  001ab80  people always wish technology seen movies best...      4\n",
       "3  001bdc0  heard venus planet without almost oxygen earth...      4\n",
       "4  002ba53  dear state senator letter argue favor keeping ...      3"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>many people car live thing dont know use car a...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>scientist nasa discussing face mars explaining...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>people always wish technology seen movies best...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001bdc0</td>\n",
       "      <td>heard venus planet without almost oxygen earth...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002ba53</td>\n",
       "      <td>dear state senator letter argue favor keeping ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T00:24:16.650198Z",
     "start_time": "2024-05-25T00:24:11.292748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = data['full_text']\n",
    "y = data['score']\n",
    "\n",
    "# vectorize the text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# transform to tensor\n",
    "X_train_tensor = torch.tensor(X_train.toarray(), dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.toarray(), dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "X_train_tensor.shape, y_train_tensor.shape"
   ],
   "id": "11aaa9ad38fc0e36",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([13845, 76499]), torch.Size([13845, 1]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T00:24:16.653564Z",
     "start_time": "2024-05-25T00:24:16.650703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build the model\n",
    "class NNModel (nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NNModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(X_train_tensor.shape[1], 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ],
   "id": "79e5a4e4a2769947",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T00:24:17.323062Z",
     "start_time": "2024-05-25T00:24:16.654070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Init the model, loss function and optimizer\n",
    "model = NNModel()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ],
   "id": "dc819667915f26cf",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T00:28:24.350743Z",
     "start_time": "2024-05-25T00:24:17.323568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train epochs\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range (epochs):\n",
    "    for i in range(0, len(X_train_tensor), batch_size):\n",
    "        X_batch = X_train_tensor[i:i+batch_size]\n",
    "        y_batch = y_train_tensor[i:i+batch_size]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "    print(f'Epoch: {epoch + 1} Loss: {loss.item()}')"
   ],
   "id": "6b52fee7f92ca0a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 0.43118494749069214\n",
      "Epoch: 2 Loss: 0.2479684054851532\n",
      "Epoch: 3 Loss: 0.17014920711517334\n",
      "Epoch: 4 Loss: 0.09109383821487427\n",
      "Epoch: 5 Loss: 0.2903982400894165\n",
      "Epoch: 6 Loss: 0.09458688646554947\n",
      "Epoch: 7 Loss: 0.17938318848609924\n",
      "Epoch: 8 Loss: 0.10566604882478714\n",
      "Epoch: 9 Loss: 0.054935380816459656\n",
      "Epoch: 10 Loss: 0.0725129023194313\n",
      "Epoch: 11 Loss: 0.04728788882493973\n",
      "Epoch: 12 Loss: 0.13730503618717194\n",
      "Epoch: 13 Loss: 0.10807614028453827\n",
      "Epoch: 14 Loss: 0.05981757119297981\n",
      "Epoch: 15 Loss: 0.10821082442998886\n",
      "Epoch: 16 Loss: 0.01250719279050827\n",
      "Epoch: 17 Loss: 0.027709277346730232\n",
      "Epoch: 18 Loss: 0.03551691398024559\n",
      "Epoch: 19 Loss: 0.023039113730192184\n",
      "Epoch: 20 Loss: 0.016198359429836273\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T00:28:24.446007Z",
     "start_time": "2024-05-25T00:28:24.352246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# evaluate the model\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    y_pred = model(X_test_tensor)\n",
    "    loss = criterion(y_pred, y_test_tensor)\n",
    "    print(f'Loss: {loss.item()}')"
   ],
   "id": "6512c4c586824f78",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.45312249660491943\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T00:28:24.457313Z",
     "start_time": "2024-05-25T00:28:24.446511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get the predictions\n",
    "import numpy as np\n",
    "X_test = test['full_text']\n",
    "X_test = vectorizer.transform(X_test)\n",
    "X_test_tensor = torch.tensor(X_test.toarray(), dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    y_pred = model(X_test_tensor)\n",
    "    test['score'] = y_pred.numpy()\n",
    "    round_sores = np.round(test['score']).astype(int)\n",
    "    \n",
    "    # write the rounded scores to the submission file\n",
    "    submission['score'] = round_sores\n",
    "    \n",
    "submission.head(5)\n",
    "    \n",
    "# %%"
   ],
   "id": "c06ae1546122ee56",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  essay_id                                          full_text  score\n",
       "0  000d118  Many people have car where they live. The thin...      1\n",
       "1  000fe60  I am a scientist at NASA that is discussing th...      3\n",
       "2  001ab80  People always wish they had the same technolog...      4"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>Many people have car where they live. The thin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>I am a scientist at NASA that is discussing th...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>People always wish they had the same technolog...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T00:31:25.456789Z",
     "start_time": "2024-05-25T00:31:25.453640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save the predictions to a csv file\n",
    "# create a submission file contains the origional test data and the predicted scores\n",
    "submission_path = '../datasets/learning-agency-lab-automated-essay-scoring-2/submission.csv'\n",
    "submission.to_csv(submission_path, index=False)"
   ],
   "id": "81c2bdbe111e4254",
   "outputs": [],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
