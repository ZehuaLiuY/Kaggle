{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Importing the Libraries",
   "id": "e382627a016ecba9"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-12T20:52:43.567566Z",
     "start_time": "2024-05-12T20:52:43.565659Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import scipy.sparse\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Loading the Data",
   "id": "fc4a890f2df5c696"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T20:52:43.591512Z",
     "start_time": "2024-05-12T20:52:43.569574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data_path = '../datasets/house-prices-advanced-regression-techniques/train.csv'\n",
    "test_data_path = '../datasets/house-prices-advanced-regression-techniques/test.csv'\n",
    "\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "print(train_data.shape)\n",
    "\n",
    "train_data.head(5)"
   ],
   "id": "ec87fa82dd9ec102",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. Data Preprocessing",
   "id": "b2b59b0dc913d470"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T20:52:43.632107Z",
     "start_time": "2024-05-12T20:52:43.603521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Identify categorical and numerical columns\n",
    "categorical_cols = train_data.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = train_data.select_dtypes(exclude=['object']).columns.tolist()\n",
    "\n",
    "# Remove the target variable from numerical columns\n",
    "numerical_cols.remove('SalePrice')\n",
    "\n",
    "# Create transformers for the preprocessing steps\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine transformers into a preprocessor with ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Create a preprocessing and modeling pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "# Split data into features and target variable\n",
    "X = train_data.drop('SalePrice', axis=1)\n",
    "y = train_data['SalePrice']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Apply preprocessing\n",
    "X_train_prepared = pipeline.fit_transform(X_train)\n",
    "X_test_prepared = pipeline.transform(X_test)\n",
    "\n",
    "# Show the shape of the processed data\n",
    "X_train_prepared.shape, X_test_prepared.shape\n"
   ],
   "id": "44cebd803c19ebd7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1168, 283), (292, 283))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4. Model Training",
   "id": "c2acdfa83df890b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T20:52:43.638106Z",
     "start_time": "2024-05-12T20:52:43.633110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class HousePricePredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HousePricePredictor, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(283, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "\n",
    "model = HousePricePredictor()\n",
    "\n",
    "loss_fn = nn.MSELoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ],
   "id": "187d712234b9f27f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HousePricePredictor(\n",
       "  (network): Sequential(\n",
       "    (0): Linear(in_features=283, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T20:52:43.642837Z",
     "start_time": "2024-05-12T20:52:43.638610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# transform the sparse matrix to dense matrix\n",
    "if isinstance(X_train_prepared, scipy.sparse.csr_matrix):\n",
    "    X_train_prepared = X_train_prepared.toarray()\n",
    "\n",
    "if isinstance(X_test_prepared, scipy.sparse.csr_matrix):\n",
    "    X_test_prepared = X_test_prepared.toarray()\n",
    "\n",
    "# transfer PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_prepared, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values.reshape(-1, 1), dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_prepared, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values.reshape(-1, 1), dtype=torch.float32)\n",
    "\n",
    "# DataLoaders\n",
    "train_data = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=32, shuffle=True)\n",
    "test_data = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=32)"
   ],
   "id": "3f8ec3568ed1da4c",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T21:11:43.266788Z",
     "start_time": "2024-05-12T21:11:34.358822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# training the model\n",
    "def train_model(model, train_data, test_data, loss_fn, optimizer, epochs=100):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_data:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(X_batch)\n",
    "            loss = loss_fn(predictions, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluate the model on the test data\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_loss = sum(loss_fn(model(X.to(device)), y.to(device)).item() for X, y in test_data) / len(test_data)\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}, Test Loss: {test_loss:.4f}')\n",
    "\n",
    "\n",
    "train_model(model, train_data, test_data, loss_fn, optimizer, epochs=250)\n"
   ],
   "id": "e4764b2cd1a34a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 307048800.0000, Test Loss: 3068908355.2000\n",
      "Epoch 20, Loss: 96858872.0000, Test Loss: 3082096600.0000\n",
      "Epoch 30, Loss: 169385664.0000, Test Loss: 3088700243.2000\n",
      "Epoch 40, Loss: 394482880.0000, Test Loss: 3089830593.6000\n",
      "Epoch 50, Loss: 167771728.0000, Test Loss: 3090012081.6000\n",
      "Epoch 60, Loss: 90636368.0000, Test Loss: 3088349633.6000\n",
      "Epoch 70, Loss: 1795566976.0000, Test Loss: 3109867612.8000\n",
      "Epoch 80, Loss: 272184448.0000, Test Loss: 3107638756.8000\n",
      "Epoch 90, Loss: 888845056.0000, Test Loss: 3108026902.4000\n",
      "Epoch 100, Loss: 135068048.0000, Test Loss: 3127627798.4000\n",
      "Epoch 110, Loss: 82273856.0000, Test Loss: 3125341148.8000\n",
      "Epoch 120, Loss: 353975776.0000, Test Loss: 3140690892.8000\n",
      "Epoch 130, Loss: 119888464.0000, Test Loss: 3130423206.4000\n",
      "Epoch 140, Loss: 230913440.0000, Test Loss: 3135767539.2000\n",
      "Epoch 150, Loss: 141166384.0000, Test Loss: 3167364241.6000\n",
      "Epoch 160, Loss: 469276576.0000, Test Loss: 3160558512.0000\n",
      "Epoch 170, Loss: 105843696.0000, Test Loss: 3156267062.4000\n",
      "Epoch 180, Loss: 392373536.0000, Test Loss: 3171972232.0000\n",
      "Epoch 190, Loss: 88133008.0000, Test Loss: 3178946668.8000\n",
      "Epoch 200, Loss: 373075136.0000, Test Loss: 3200693209.6000\n",
      "Epoch 210, Loss: 46520128.0000, Test Loss: 3198096401.6000\n",
      "Epoch 220, Loss: 229717328.0000, Test Loss: 3203459792.0000\n",
      "Epoch 230, Loss: 170491456.0000, Test Loss: 3212977046.4000\n",
      "Epoch 240, Loss: 123708032.0000, Test Loss: 3205508731.2000\n",
      "Epoch 250, Loss: 155062512.0000, Test Loss: 3234819299.2000\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b17bb864959499ba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e9816a08d850db8a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
